---
subtitle: 'Gametocyte Development in <i>Plasmodium berghei</i>'
title: |
  ![](/Users/Andy/GCSKO/GCSKO_analysis_git/GCSKO_logo.jpg){width=300px}  
  10X Quality Control
author: "[Andrew Russell](https://ajcrussell.wixsite.com/mysite/about)"
institute: Wellcome Sanger Institute
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
  html_notebook:
    theme: cosmo
    toc: yes
    toc_depth: 3
    #toc_float: yes
    df_print: paged
---
***
# 1. Introduction and Aims {.tabset}

Two datasets were generated using the 10X Genomics Chromium 3' scRNA-Seq platform:

```{r, echo=FALSE, results='asis'}
## load knitr to display table
library(knitr)
## make dataframe
species <- c("pb", "pb")
experiment_name <- c('straight bleed experiment','1:1 mix experiment')
run_number <- c("22252", "24284")
lane_number <- c("5", "1 & 2")
sequencer <- c("Hiseq 4000", "Hiseq 2500")
approximate_number_of_cells <- c("30,000", "5,000")
employ.data <- data.frame(species, experiment_name, run_number, lane_number, sequencer, approximate_number_of_cells, stringsAsFactors=FALSE)
## print dataframe
kable(employ.data)
```

This data has been processed using CellRanger into counts tables. This initial analysis gave the following metrics:

<b>Pb straight bleed experiment (run #: 22252 lane 5 Hiseq 4000)) (AKA 30K cells):</b>

<div style="width:500px; height:400px">![](10x-screenshots/22252_5_cellranger_screenshot1.png)</div>
<div style="width:500px; height:200px">![](10x-screenshots/22252_5_cellranger_screenshot2.png)</div>

<b>Pb 1:1 mix experiment (run #: 24284 lanes 1 and 2 (Hiseq 2500)):</b>

<div style="width:500px; height:400px">![](10x-screenshots/24284_cellranger_screenshot1.png)</div>
<div style="width:500px; height:200px">![](10x-screenshots/24284_cellranger_screenshot2.png)</div>


<b>We will load this data in and for each run:</b>

A. Define 'cells'

B. Filter poor quality cells out

C. Dimensionality Reduction and Clustering 

D. Remove Doublets

E. Life Cycle Stage (Using Bulk RNA-Seq Correlation)

# 2. Read in the data  {.tabset}

### Load the required packages

```{r, echo = FALSE}
## Seurat is needed for most of this script
if(require("Seurat", quietly = TRUE)){
    print("Seurat is loaded correctly")
} else {
    print("trying to install Seurat")
    install.packages("Seurat")
    if(require(Seurat)){
        print("Seurat installed and loaded")
    } else {
        stop("could not install Seurat")
    }
}

## cowplot is needed for plots
if(require("cowplot")){
    print("cowplot is loaded correctly")
} else {
    print("trying to install cowplot")
    install.packages("cowplot")
    if(require(cowplot)){
        print("cowplot installed and loaded")
    } else {
        stop("could not install cowplot")
    }
}

## gridExtra is needed for grid graphics to plot multiple plots in the same view
if(require("gridExtra")){
    print("gridExtra is loaded correctly")
} else {
    print("trying to install gridExtra")
    install.packages("gridExtra")
    if(require(gridExtra)){
        print("gridExtra installed and loaded")
    } else {
        stop("could not install gridExtra")
    }
}

##for grid.arrange function to change size of title
if(require("grid")){
    print("grid is loaded correctly")
} else {
    print("trying to install grid")
    install.packages("grid")
    if(require(grid)){
        print("grid installed and loaded")
    } else {
        stop("could not install grid")
    }
}

## for doing bulk correlation calculations
if(require("Hmisc")){
    print("Hmisc is loaded correctly")
} else {
    print("trying to install Hmisc")
    install.packages("Hmisc")
    if(require(Hmisc)){
        print("Hmisc installed and loaded")
    } else {
        stop("could not install Hmisc")
    }
}

## dplyr is needed to work with data frames
if(require("dplyr")){
    print("dplyr is loaded correctly")
} else {
    print("trying to install dplyr")
    install.packages("dplyr")
    if(require(dplyr)){
        print("dplyr installed and loaded")
    } else {
        stop("could not install dplyr")
    }
}

## set the seed for both the mixture models and also for the sample function later on:
set.seed(-92497)
```

### Import GTF file

This will be helpful later on. This contains annotations for each gene:
```{r}
##Import gtf file:
gtf <- read.table("/Users/Andy/GCSKO/GCSKO_analysis_git/data/Reference/Pberghei.gtf", sep="\t", header = FALSE)
head(gtf)
```

# 5K data {.tabset}

## Read in the Data

```{r}
tenx5k_raw_data <- Read10X("tenx_24284")

#'control' object
tenx5k <- CreateSeuratObject(counts = tenx5k_raw_data, min.cells = 0, min.features = 0, project = "GCSKO")
tenx5k@meta.data$experiment <- "tenx5k"
```

## A. Defining Cells vs. Background

knee plot
```{r}
## interesting reference material can be found here: https://hemberg-lab.github.io/scRNA.seq.course/processing-raw-scrna-seq-data.html 
## get the nUMIs
umi_per_barcode <- as.data.frame(tenx5k@meta.data$nCount_RNA)
## remove zeros as these have issues when you log them and make the model later:
umi_per_barcode <- as.data.frame(umi_per_barcode[!(umi_per_barcode$`tenx5k@meta.data$nCount_RNA`==0), ])
# get a rank for each barcode
barcode_rank <- rank(-umi_per_barcode[,1])
# then make into a list
lib_size <- (umi_per_barcode[,1])
#then log this
log_lib_size <- log10(umi_per_barcode[,1])
#plot(barcode_rank, log_lib_size, xlim=c(1,100000))
```

```{r}
o <- order(barcode_rank)
log_lib_size <- log_lib_size[o]
barcode_rank <- barcode_rank[o]

#rawdiff <- diff(log_lib_size)/diff(barcode_rank)
#inflection <- which(rawdiff == min(rawdiff[100:length(rawdiff)], na.rm=TRUE))

#plot(barcode_rank, log_lib_size, xlim=c(1,8000))
#abline(v=inflection, col="red", lwd=4)
```
make a mixture model to determine the knee of the plot
```{r}
set.seed(-92497)
# mixture model
require("mixtools")
mix <- normalmixEM(log_lib_size)
plot(mix, which=2, xlab2="log(mol per cell)")
```

```{r}
p1 <- dnorm(log_lib_size, mean=mix$mu[1], sd=mix$sigma[1])
p2 <- dnorm(log_lib_size, mean=mix$mu[2], sd=mix$sigma[2])
if (mix$mu[1] < mix$mu[2]) {
    split <- min(log_lib_size[p2 > p1])
} else {
    split <- min(log_lib_size[p1 > p2])
}
split
```

```{r}
log_barcode_rank <- log10(barcode_rank)
plot(log_barcode_rank, log_lib_size, xlim=c(1,6))
abline(h=split, col="red")
```

Final Figures:
```{r}
require(scales) # to access break formatting functions
df_barcodes <- as.data.frame(cbind(barcode_rank, log_lib_size), row.names = NULL)
#add a column for if it is a cell
df_barcodes$cell = rownames(df_barcodes) %in% which(df_barcodes$log_lib_size > split)
#change value to a numeric
df_barcodes$cell <- as.numeric(df_barcodes$cell)
df_barcodes$cell[df_barcodes$cell<1] <- 2
df_barcodes$cell[df_barcodes$cell == 1] <- "Cells"
df_barcodes$cell[df_barcodes$cell == 2] <- "Background"
```

```{r}
library(scales) # to access break formatting functions
barcode_plot <- ggplot(df_barcodes, aes(x=barcode_rank, y=log_lib_size, colour = cell, theme_size = 40)) +
  geom_point(size = 1, shape = 16) +
  geom_segment(aes(x = 0, y = split, xend = 7762, yend = split), colour = "black", alpha = 0.01) +
  geom_segment(aes(x = 7762, y = 0, xend = 7762, yend = split), colour = "black", alpha = 0.01) +
  scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x), labels = trans_format("log10", math_format(10^.x))) +
  scale_y_continuous(labels = c('0',bquote(10^1), bquote(10^2), bquote(10^3), bquote(10^4))) + annotation_logticks() +
  scale_color_manual(values=c("#bdbdbd", "#5ba43a"), labels = c("Background", "Cells")) +
  theme(legend.position="right", text = element_text(size=25), legend.text=element_text(size=25), axis.text=element_text(size=25)) +
  labs(x = "Barcodes", y = "UMI Counts", colour="Cell Designation") +
  guides(colour = guide_legend(override.aes = list(size=10))) +
  coord_fixed() +
  theme_light()

barcode_plot
```

save:
```{r}
ggsave("barcode_plot_5k.png", plot = barcode_plot, device = "png", height = 15, width = 15, units = "cm", path = "~/images_to_export")
```

so the number of cells that is retained is:
```{r, echo = FALSE}
table(df_barcodes$cell)
```

Filter the object:
```{r}
upb <- data.frame(nCount_RNA = tenx5k@meta.data$nCount_RNA, row.names = rownames(tenx5k@meta.data))
upb$rank <- NA
order.scores <- order(upb$nCount_RNA, decreasing = TRUE)
upb$rank[order.scores] <- 1:nrow(upb)
head(upb)
keep_cells <- rownames(upb[which(upb$rank < 7763),])
pb_sex <- SubsetData(tenx5k, cells = keep_cells, do.clean = TRUE, subset.raw = TRUE)
```

## B. Filter Out Poor-Quality Cells

plot the cells:
```{r}
#inspect the ngenes and nUMI
gene_plot_5k <- VlnPlot(object = pb_sex, features = "nFeature_RNA", pt.size = 0.01, do.return = TRUE)

gene_plot_5k <- gene_plot_5k + 
  geom_abline(intercept = 200, col="blue") +
  labs(x = "",y = "nGene", title = "Genes per cell") +
  theme_classic() +
  scale_fill_manual(values="grey") +
  scale_y_continuous(limits = c(0, 3000)) +
  theme(legend.position="none", axis.text.x = element_blank(), axis.ticks.x=element_blank(), text = element_text(size=20), legend.text=element_text(size=20), axis.text=element_text(size=20), axis.text.y=element_text(colour="black"))

#nUMI plot
numi_plot_5k <- VlnPlot(object = pb_sex, features = "nCount_RNA", pt.size = 0.01, do.return = TRUE)

numi_plot_5k <- numi_plot_5k +
  labs(x = "",y = "nUMI", title = "UMIs per cell") +
  theme_classic() +
  scale_fill_manual(values="grey") +
  scale_y_continuous(limits = c(0, 3000)) +
  theme(legend.position="none", axis.text.x = element_blank(), axis.ticks.x=element_blank(), text = element_text(size=20), legend.text=element_text(size=20), axis.text=element_text(size=20), axis.text.y=element_text(colour="black"))

#plot together
grid.arrange(gene_plot_5k, numi_plot_5k, ncol = 2, top=textGrob("5K cells 10X", gp=gpar(fontsize=15,font=8)))
```

### Filter Mitochondrial

Mitochondrial cell counts
```{r}
## extract mitochondrial genes 
mito_genes <- gtf[which(gtf$V3 == "rRNA"),]$V9
mito_genes <- gsub(";.*","", gsub("gene_id ", "", mito_genes))
paste("These are the mitochondrial genes")
head(mito_genes)

## make a percentage mitocondrial for each cell (this will work as long as you filter cells out with zero counts)
pb_sex <- PercentageFeatureSet(pb_sex, features = which(rownames(counts) %in% mito_genes), col.name = "percent.mt")
```

plot percentage mitochondrial
```{r}
## plot for percentage of mitochondrial reads
v1 <- VlnPlot(object = pb_sex, features = "percent.mt", pt.size = 0.01) +
  ## add a line where we will filter
  geom_abline(intercept = 20, col="blue") +
  ## change labels
  labs(x = "",y = "% Mitochondrial Reads", title = "Mitochondrial per cell") +
  ## remove legend
  theme(legend.position = "none") +
  ## change appearance
  theme_classic() +
  scale_fill_manual(values="grey") +
  #scale_y_continuous(limits = c(0, 100)) +
  theme(legend.position="none", axis.text.x = element_blank(), axis.ticks.x=element_blank(), text = element_text(size=20), legend.text=element_text(size=20), axis.text=element_text(size=20), axis.text.y=element_text(colour="black"))

## print
v1

## save
#ggsave("~/images_to_export/QC_10X_mito_violin.png", plot = QC_mito_violin, device = "png", path = NULL, scale = 1, width = 15, height = 10, units = "cm", dpi = 300, limitsize = TRUE)
```


```{r}
df <- data.frame(nCount = log10(pb_sex@meta.data$nCount_RNA), nGenes = pb_sex@meta.data$nFeature_RNA)

## add this if you can get mitochondrial
# percent_mt = pb_sex@meta.data$percent.mt
```

```{r, fig.height = 8, fig.width = 8}
## plot main dotplot
plot1 <- ggplot(df, aes(x = nCount, y = nGenes)) + 
  geom_point(aes(), size = 0.1) +
  geom_rug() + 
  scale_y_continuous(name = "Number of Detected Genes") + 
  scale_x_continuous(name = "log10(Number of Total UMI)") + 
  theme_pubr() +
  theme(legend.position = "bottom") +
  geom_hline(yintercept=200)

## plot density plot x
dens1 <- ggplot(df, aes(x = nCount)) + 
  geom_density(alpha = 0.2) + 
  theme_void() + 
  theme(legend.position = "none")

## plot density plot y
dens2 <- ggplot(df, aes(x = nGenes)) + 
  geom_density(alpha = 0.2) + 
  theme_void() + 
  theme(legend.position = "none") + 
  coord_flip()

## plot together
QC_composite_plot <- dens1 + plot_spacer() + plot1 + dens2 + plot_layout(ncol = 2, nrow = 2, widths = c(4, 1), heights = c(1, 4))

## print
QC_composite_plot
```

```{r}
## save
ggsave("~/images_to_export/QC_10X_composite_plot.png", plot = QC_composite_plot, device = "png", path = NULL, scale = 1, width = 20, height = 20, units = "cm", dpi = 300, limitsize = TRUE)
```


The threshold used in the malaria cell atlas was 230 for Pb but this is dependent on sequencing depth etc.
We can plot the number of cells recovered for a range of thresholds:
```{r}
nrow(pb_sex@meta.data[pb_sex@meta.data$nFeature_RNA > 150, ])
nrow(pb_sex@meta.data[pb_sex@meta.data$nFeature_RNA > 200, ])
nrow(pb_sex@meta.data[pb_sex@meta.data$nFeature_RNA > 230, ])
```

Since we have already filtered on nUMI, we will filter with 200.

```{r}
## number of cells before filtering
pb_sex_pre_filter_nCells <- nrow(pb_sex@meta.data)
## filter object
pb_sex <- subset(pb_sex, subset = nFeature_RNA > 200)
## number of cells after filtering
pb_sex_post_filter_nCells <- nrow(pb_sex@meta.data)
## print results of filtering
pb_sex_pre_filter_nCells
pb_sex_post_filter_nCells
```

save ngene plot
```{r}
#ggsave("ngene_plot.pdf", plot = gene1, device = "pdf", height = 5, width = 5, units = "in", path = "/Users/ar19/Desktop/PhD/GCSKO_Analysis")
```

```{r, echo = FALSE}
pb_sex_pre_filter_nCells - pb_sex_post_filter_nCells
```
cells were removed by filtering on number of genes.

## C. Dimensionality Reduction and Clustering 

normalise
```{r}
## normalise object
pb_sex <- NormalizeData(pb_sex, normalization.method = "LogNormalize", scale.factor = 10000)
```

find variable genes
```{r}
pb_sex <- FindVariableFeatures(pb_sex, selection.method = "vst", nfeatures = 2000)
```

scale the data
```{r}
all.genes <- rownames(pb_sex)
pb_sex <- ScaleData(pb_sex, features = all.genes)
```

```{r}
pb_sex <- RunPCA(pb_sex, features = VariableFeatures(object = pb_sex))
```

```{r}
DimPlot(pb_sex, reduction = "pca")
```

```{r}
ElbowPlot(pb_sex, ndims = 30, reduction = "pca")
```

```{r}
pb_sex <- FindNeighbors(pb_sex, dims = 1:21)
pb_sex <- FindClusters(pb_sex, resolution = 1)
```

```{r}
pb_sex <- RunUMAP(pb_sex, dims = 1:12, seed.use = 2000, n.neighbors = 10)
DimPlot(pb_sex, reduction = "umap", group.by = "ident", label = TRUE)

## These are the parameters used in the merge UMAP
#pb_sex <- RunUMAP(pb_sex, reduction = "pca", dims = 1:10, n.neighbors = 150, seed.use = 1234, min.dist = 0.4, repulsion.strength = 0.03, local.connectivity = 150)
```

colour with a few marker genes:

```{r, fig.height = 6, fig.width = 8}
# PBANKA-0515000 - p25 - female
# PBANKA-1212600 - HAP2 - male
# PBANKA-0600600 - NEK3 - male
# PBANKA-0831000 - MSP1 - late asexual
# PBANKA-1315700 - RON2 - (asexuals and some male?)
# PBANKA-0416100 - dynenin heavy chain - male - used in 820 line
# PBANKA-1319500 - CCP2 - female - used in 820 line 
# PBANKA-1437500 - AP2-G - seuxal commitment gene
# PBANKA-1102200 - MSP8 - early asexual (from Bozdech paper)

FeaturePlot(pb_sex, features = c("PBANKA-0515000", "PBANKA-1212600","PBANKA-0600600", "PBANKA-0831000", "PBANKA-1315700", "PBANKA-0416100", "PBANKA-1319500", "PBANKA-1437500", "PBANKA-1102200"))
```

## D. Remove Doublets

```{r}
doubletFinder_v3 <- function(seu, PCs, pN = 0.25, pK, nExp, reuse.pANN = FALSE, sct = FALSE) {
  require(Seurat); require(fields); require(KernSmooth)

  ## Generate new list of doublet classificatons from existing pANN vector to save time
  if (reuse.pANN != FALSE ) {
    pANN.old <- seu@meta.data[ , reuse.pANN]
    classifications <- rep("Singlet", length(pANN.old))
    classifications[order(pANN.old, decreasing=TRUE)[1:nExp]] <- "Doublet"
    seu@meta.data[, paste("DF.classifications",pN,pK,nExp,sep="_")] <- classifications
    return(seu)
  }

  if (reuse.pANN == FALSE) {
    ## Make merged real-artifical data
    real.cells <- rownames(seu@meta.data)
    data <- seu@assays$RNA@counts[, real.cells]
    n_real.cells <- length(real.cells)
    n_doublets <- round(n_real.cells/(1 - pN) - n_real.cells)
    print(paste("Creating",n_doublets,"artificial doublets...",sep=" "))
    real.cells1 <- sample(real.cells, n_doublets, replace = TRUE)
    real.cells2 <- sample(real.cells, n_doublets, replace = TRUE)
    doublets <- (data[, real.cells1] + data[, real.cells2])/2
    colnames(doublets) <- paste("X", 1:n_doublets, sep = "")
    data_wdoublets <- cbind(data, doublets)

    ## Store important pre-processing information
    orig.commands <- seu@commands

    ## Pre-process Seurat object
    if (sct == FALSE) {
      print("Creating Seurat object...")
      seu_wdoublets <- CreateSeuratObject(counts = data_wdoublets)

      print("Normalizing Seurat object...")
      seu_wdoublets <- NormalizeData(seu_wdoublets,
                                     normalization.method = orig.commands$NormalizeData.RNA@params$normalization.method,
                                     scale.factor = orig.commands$NormalizeData.RNA@params$scale.factor,
                                     margin = orig.commands$NormalizeData.RNA@params$margin)

      print("Finding variable genes...")
      seu_wdoublets <- FindVariableFeatures(seu_wdoublets,
                                            selection.method = orig.commands$FindVariableFeatures.RNA$selection.method,
                                            loess.span = orig.commands$FindVariableFeatures.RNA$loess.span,
                                            clip.max = orig.commands$FindVariableFeatures.RNA$clip.max,
                                            mean.function = orig.commands$FindVariableFeatures.RNA$mean.function,
                                            dispersion.function = orig.commands$FindVariableFeatures.RNA$dispersion.function,
                                            num.bin = orig.commands$FindVariableFeatures.RNA$num.bin,
                                            binning.method = orig.commands$FindVariableFeatures.RNA$binning.method,
                                            nfeatures = orig.commands$FindVariableFeatures.RNA$nfeatures,
                                            mean.cutoff = orig.commands$FindVariableFeatures.RNA$mean.cutoff,
                                            dispersion.cutoff = orig.commands$FindVariableFeatures.RNA$dispersion.cutoff)

      print("Scaling data...")
      seu_wdoublets <- ScaleData(seu_wdoublets,
                                 features = orig.commands$ScaleData.RNA$features,
                                 model.use = orig.commands$ScaleData.RNA$model.use,
                                 do.scale = orig.commands$ScaleData.RNA$do.scale,
                                 do.center = orig.commands$ScaleData.RNA$do.center,
                                 scale.max = orig.commands$ScaleData.RNA$scale.max,
                                 block.size = orig.commands$ScaleData.RNA$block.size,
                                 min.cells.to.block = orig.commands$ScaleData.RNA$min.cells.to.block)

      print("Running PCA...")
      seu_wdoublets <- RunPCA(seu_wdoublets,
                              features = orig.commands$ScaleData.RNA$features,
                              npcs = length(PCs),
                              rev.pca =  orig.commands$RunPCA.RNA$rev.pca,
                              weight.by.var = orig.commands$RunPCA.RNA$weight.by.var,
                              verbose=FALSE)
      pca.coord <- seu_wdoublets@reductions$pca@cell.embeddings[ , PCs]
      cell.names <- rownames(seu_wdoublets@meta.data)
      nCells <- length(cell.names)
      rm(seu_wdoublets); gc() # Free up memory
    }

    if (sct == TRUE) {
      require(sctransform)
      print("Creating Seurat object...")
      seu_wdoublets <- CreateSeuratObject(counts = data_wdoublets)

      print("Running SCTransform...")
      seu_wdoublets <- SCTransform(seu_wdoublets)

      print("Running PCA...")
      seu_wdoublets <- RunPCA(seu_wdoublets, npcs = length(PCs))
      pca.coord <- seu_wdoublets@reductions$pca@cell.embeddings[ , PCs]
      cell.names <- rownames(seu_wdoublets@meta.data)
      nCells <- length(cell.names)
      rm(seu_wdoublets); gc()
    }

    ## Compute PC distance matrix
    print("Calculating PC distance matrix...")
    dist.mat <- fields::rdist(pca.coord)

    ## Compute pANN
    print("Computing pANN...")
    pANN <- as.data.frame(matrix(0L, nrow = n_real.cells, ncol = 1))
    rownames(pANN) <- real.cells
    colnames(pANN) <- "pANN"
    k <- round(nCells * pK)
    for (i in 1:n_real.cells) {
      neighbors <- order(dist.mat[, i])
      neighbors <- neighbors[2:(k + 1)]
      neighbor.names <- rownames(dist.mat)[neighbors]
      pANN$pANN[i] <- length(which(neighbors > n_real.cells))/k
    }

    print("Classifying doublets..")
    classifications <- rep("Singlet",n_real.cells)
    classifications[order(pANN$pANN[1:n_real.cells], decreasing=TRUE)[1:nExp]] <- "Doublet"
    seu@meta.data[, paste("pANN",pN,pK,nExp,sep="_")] <- pANN[rownames(seu@meta.data), 1]
    seu@meta.data[, paste("DF.classifications",pN,pK,nExp,sep="_")] <- classifications
    return(seu)
  }
}
## usage: https://rdrr.io/github/chris-mcginnis-ucsf/DoubletFinder/man/doubletFinder_v3.html
## source: https://github.com/chris-mcginnis-ucsf/DoubletFinder/blob/master/R/doubletFinder_v3.R
```



```{r}
#devtools::install_github('chris-mcginnis-ucsf/DoubletFinder')
#library(doubletFinder) #allows removal of doublets
# the tutorial recommends using this as an approximation:
#nExp_poi <- round(0.15*nrow(pb_sex@meta.data))
#but a more appropriate approximation is that the expected number of doublets is ~1% per 1000 cells so:
nExp_poi <- round((0.01*(nrow(pb_sex@meta.data)/1000))*nrow(pb_sex@meta.data))
#run doublet finder:
pb_sex <- doubletFinder_v3(pb_sex, PCs = 1:21, pN = 0.25, pK = 0.01, nExp = nExp_poi, reuse.pANN = FALSE, sct = FALSE)
```

results in:
```{r}
table(pb_sex@meta.data$DF.classifications_0.25_0.01_440)
```

visualise where doublets are:
```{r}
doublet.cells <- c(rownames(pb_sex@meta.data[pb_sex@meta.data$DF.classifications_0.25_0.01_440 == "Doublet",]))
d1 <- DimPlot(pb_sex, reduction = "umap", cells.highlight = doublet.cells, sizes.highlight = 2)
#TSNEPlot(object = pb_sex, cells.highlight = doublet.cells, do.return = TRUE, )
doublet1 <- d1 + coord_fixed() + theme(axis.text.x=element_blank())
doublet1
```

```{r}
VlnPlot(object = pb_sex, features = "pANN_0.25_0.01_440", point.size.use = 0.1, do.return = TRUE)
```


```{r}
df <- pb_sex@meta.data
df <- df[,c(6,8)]
df <- data.frame(rbind(table(df)))
df$pc_doublet <- ((df[,1])/((df[,1]) + df[,2]))*100
df$cluster <- rownames(df)
#plot
kable(df[order(df$pc_doublet),])
```

```{r}
ggplot(data=df, aes(x=cluster, y=pc_doublet)) +
  geom_col(fill="steelblue") +
  theme_minimal()
```

# these got renamed in the 

The clusters with the least doublets:
11 - female (mature)


13 - asex 10
4 - asex 1
6 - asex 2
10 - male (mature)
9 - asex 9
2 - asex 3
12 - female (early)
5 - asex 5
7 - asex 8
8 - sex (early male and female)
0 - asex 6
1 - asex 7
3 - asex 4

remove doublets:
```{r}
keep_singlets <- rownames(pb_sex@meta.data[pb_sex@meta.data$DF.classifications_0.25_0.01_440 == "Singlet",])
pb_sex_filtered <- subset(pb_sex, cells = keep_singlets, subset.raw = TRUE)
pb_sex
pb_sex_filtered
```

## E. Life Cycle Stage (Using Bulk RNA-Seq Correlation)

Add in bulk data predictions

### hoo et al.
```{r}
#Pb Prediction correlations with bulk data (asexual hoo): 

#Load in required package:
library(Hmisc)
#Cooerce expression data into a matrix and load in the reference timecourse data:
x10 <- as.matrix(pb_sex_filtered@assays$RNA@data)
rownames(x10) <- gsub("-", "_", rownames(x10))
#read in bulk data:
hoo<-as.matrix(read.table("Reference_bulk_data/hoo_berg2.txt",header=T, row.names=1))
#Make a blank dataframe in which to add prediction:
df <- data.frame(matrix(ncol = 4, nrow = 0))
colnames(df) <- c("Prediction(Spearman)","r(Spearman)","Prediction(Pearsons)","r(Pearsons)")
#Do correlations with bulk data using both Spearman and Pearson (and the top 1000 genes):
for (i in 1:ncol(x10))
{
  shared<-intersect(row.names(as.matrix(head(sort(x10[,i], decreasing=TRUE),1000))),row.names(hoo))
  step0<-rcorr(x10[shared,i],hoo[shared,1:12],type = "spearman")
  step1<-as.matrix(t(step0$r[2:13,1]))
  step2<-rcorr(x10[shared,i],hoo[shared,1:12],type = "pearson")
  step3<-as.matrix(t(step2$r[2:13,1]))
  step4<-cbind(colnames(step1)[which.max(step1)],step1[which.max(step1)],colnames(step3)[which.max(step3)],step3[which.max(step3)])
  colnames(step4) <- c("Prediction(Spearman)","r(Spearman)","Prediction(Pearsons)","r(Pearsons)")
  rownames(step4)<-colnames(x10)[i]
  df<-rbind(df,step4)
}
#Write out data into a csv file:
#write.csv(dfringr,file="/Users/ar19/Desktop/PhD/AR04_GCSKO_project/All_mutants_Feb_2018/predictionpbcombined.csv")
#Change the format of the output to make it more readable:
#gsub("Pb_","", dfringr[,1]) - Make predictions into 18hr.dat format:

#spearman:
df[,1] <- gsub("Pb_","", df[,1])
#Remove hr.dat from list:
df[,1] <- gsub("hr.dat","", df[,1])
#Check - dfringr[,1]
#Make into a number:
df[,1] <- as.numeric(df[,1])
df[,2] <- as.numeric(as.character(df[,2]))

#pearson:
df[,3] <- gsub("Pb_","", df[,3])
#Remove hr.dat from list:
df[,3] <- gsub("hr.dat","", df[,3])
#Check - dfringr[,1]
#Make into a number:
df[,3] <- as.numeric(df[,3])
df[,4] <- as.numeric(as.character(df[,4]))
#add to 10X object:
pb_sex_filtered <- AddMetaData(pb_sex_filtered, metadata = df)
```

### Kasia's data
Can also do with Kasia's timecourse data:
```{r}
kas<-as.matrix(read.table("Reference_bulk_data/AP2OETC.txt",header=T, row.names=1))
#Make a blank dataframe in which to add prediction:
dfs <- data.frame(matrix(ncol = 4, nrow = 0))
colnames(dfs) <- c("ID","Prediction","r (Pearson)")
#Do correlations with bulk data using both Spearman and Pearson (and the top 1000 genes):
for (i in 1:ncol(x10))
{
  shared<-intersect(row.names(as.matrix(head(sort(x10[,i], decreasing=TRUE),1000))),rownames(kas))
  step0<-rcorr(x10[shared,i],kas[shared,1:10],type = "spearman")
  step1<-as.matrix(t(step0$r[2:11,1]))
  step2<-rcorr(x10[shared,i],kas[shared,1:10],type = "pearson")
  step3<-as.matrix(t(step2$r[2:11,1]))
  step4<-cbind(colnames(step1)[which.max(step1)],step1[which.max(step1)],colnames(step3)[which.max(step3)],step3[which.max(step3)])
  colnames(step4) <- c("Prediction(Spearman)","r(Spearman)","Prediction(Pearsons)","r(Pearsons)")
  rownames(step4)<-colnames(x10)[i]
  dfs<-rbind(dfs,step4)
}
#Write out data into a csv file:
#write.csv(df,file="/Users/ar19/Desktop/PhD/AR04_GCSKO_project/All_mutants_Feb_2018/predictionkasiacombined.csv")

#Change the format of the output to make it more readable:
#gsub("Pb_","", dfs[,1]) - Make predictions into 18hr.dat format:
dfs[,1] <- gsub("X","", dfs[,1])
#Make into a number:
dfs[,1] <- as.numeric(dfs[,1])
#Make into a number:
dfs[,2] <- as.numeric(as.character(dfs[,2]))

#gsub("Pb_","", dfs[,1]) - Make predictions into 18hr.dat format:
dfs[,3] <- gsub("X","", dfs[,3])
#Make into a number:
dfs[,3] <- as.numeric(dfs[,3])
#dfs[,1]
#Make into a number:
dfs[,4] <- as.numeric(as.character(dfs[,4]))

colnames(dfs) <- c('Prediction(Spearman)_Kasia', 'r(Spearman)_Kasia', 'Prediction(Pearson)_Kasia', 'r(Pearson)_Kasia')
#add to Seurat:
#add to 10X object:
pb_sex_filtered <- AddMetaData(pb_sex_filtered, dfs)
```

```{r}
pb_sex_filtered <- RunUMAP(pb_sex_filtered, dims = 1:21, seed.use = 200, n.neighbors = 15)
DimPlot(pb_sex_filtered, reduction = "umap", group.by = "ident", label = TRUE)
```

Confirm life cycle designations:

```{r}
pb_sex_filtered@meta.data
FeaturePlot(pb_sex_filtered, features = c("Prediction(Spearman)_Kasia", "Prediction(Spearman)"))
```

optimse UMAP

```{r}
pb_sex_filtered <- RunPCA(pb_sex_filtered, features = VariableFeatures(object = pb_sex_filtered))
```

```{r}
ElbowPlot(pb_sex_filtered, ndims = 30, reduction = "pca")
```

```{r}
pb_sex_filtered <- RunUMAP(pb_sex_filtered, dims = 1:8, seed.use = 300, n.neighbors = 60, min.dist = 0.5, repulsion.strength = 0.05, local.connectivity = 20)
DimPlot(pb_sex_filtered, reduction = "umap", group.by = "ident", label = TRUE)
```

recluster:
```{r}
pb_sex_filtered <- FindNeighbors(pb_sex_filtered, dims = 1:18)
pb_sex_filtered <- FindClusters(pb_sex_filtered, resolution = 3)
DimPlot(pb_sex_filtered, reduction = "umap", group.by = "ident", label = TRUE)
```


# 30K data {.tabset}

## Read in the Data

```{r}
tenx30k_raw_data <- Read10X("tenx_22252_5")

#'control' object
tenx30k <- CreateSeuratObject(counts = tenx30k_raw_data, min.cells = 0, min.features = 0, project = "GCSKO")
tenx30k@meta.data$experiment <- "tenx30k"
```

## A. Defining Cells vs. Background

knee plot
```{r}
## interesting reference material can be found here: https://hemberg-lab.github.io/scRNA.seq.course/processing-raw-scrna-seq-data.html 
## get the nUMIs
umi_per_barcode <- as.data.frame(tenx30k@meta.data$nCount_RNA)
## remove zeros as these have issues when you log them and make the model later:
umi_per_barcode <- as.data.frame(umi_per_barcode[!(umi_per_barcode$`tenx30k@meta.data$nCount_RNA`==0), ])
# get a rank for each barcode
barcode_rank <- rank(-umi_per_barcode[,1])
# then make into a list
lib_size <- (umi_per_barcode[,1])
#then log this
log_lib_size <- log10(umi_per_barcode[,1])
#plot(barcode_rank, log_lib_size, xlim=c(1,100000))
```

```{r}
o <- order(barcode_rank)
log_lib_size <- log_lib_size[o]
barcode_rank <- barcode_rank[o]

#rawdiff <- diff(log_lib_size)/diff(barcode_rank)
#inflection <- which(rawdiff == min(rawdiff[100:length(rawdiff)], na.rm=TRUE))

#plot(barcode_rank, log_lib_size, xlim=c(1,8000))
#abline(v=inflection, col="red", lwd=4)
```

make a mixture model to determine the knee of the plot
```{r}
set.seed(-92497)
# mixture model
require("mixtools")
mix <- normalmixEM(log_lib_size)
plot(mix, which=2, xlab2="log(mol per cell)")
```

```{r}
p1 <- dnorm(log_lib_size, mean=mix$mu[1], sd=mix$sigma[1])
p2 <- dnorm(log_lib_size, mean=mix$mu[2], sd=mix$sigma[2])
if (mix$mu[1] < mix$mu[2]) {
    split <- min(log_lib_size[p2 > p1])
} else {
    split <- min(log_lib_size[p1 > p2])
}
split
```

```{r}
log_barcode_rank <- log10(barcode_rank)
plot(log_barcode_rank, log_lib_size, xlim=c(1,6))
abline(h=split, col="red")
```

Final Figures:
```{r}
require(scales) # to access break formatting functions
df_barcodes <- as.data.frame(cbind(barcode_rank, log_lib_size), row.names = NULL)
#add a column for if it is a cell
df_barcodes$cell = rownames(df_barcodes) %in% which(df_barcodes$log_lib_size > split)
#change value to a numeric
df_barcodes$cell <- as.numeric(df_barcodes$cell)
df_barcodes$cell[df_barcodes$cell<1] <- 2
df_barcodes$cell[df_barcodes$cell == 1] <- "Cells"
df_barcodes$cell[df_barcodes$cell == 2] <- "Background"
ncells <- as.numeric(data.frame(table(df_barcodes$cell))[2,2])

library(scales) # to access break formatting functions
barcode_plot_30k <- ggplot(df_barcodes, aes(x=barcode_rank, y=log_lib_size, colour = cell, theme_size = 40)) +
  geom_point(size = 1, shape = 15) +
  geom_segment(aes(x = 0, y = split, xend = ncells, yend = split), colour = "black", alpha = 0.01) +
  geom_segment(aes(x = ncells, y = 0, xend = ncells, yend = split), colour = "black", alpha = 0.01) +
  scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x), labels = trans_format("log10", math_format(10^.x))) +
  scale_y_continuous(labels = c('0',bquote(10^1), bquote(10^2), bquote(10^3), bquote(10^4))) + annotation_logticks() +
  scale_color_manual(values=c("#bdbdbd", "#5ba43a"), labels = c("Background", "Cells")) +
  theme(legend.position="right", text = element_text(size=20), legend.text=element_text(size=20), axis.text=element_text(size=20)) +
  labs(x = "Barcodes", y = "UMI Counts", colour="Cell Designation") +
  guides(colour = guide_legend(override.aes = list(size=10))) +
  coord_fixed() +
  theme_light()

barcode_plot_30k
```

save:
```{r}
ggsave("barcode_plot_30k.png", plot = barcode_plot_30k, device = "png", height = 10, width = 10, units = "cm", path = "~/images_to_export")
```

so the number of cells that is retained is:
```{r, echo = FALSE}
table(df_barcodes$cell)
```

Filter the object:
```{r}
upb <- data.frame(nCount_RNA = tenx30k@meta.data$nCount_RNA, row.names = rownames(tenx30k@meta.data))
upb$rank <- NA
order.scores <- order(upb$nCount_RNA, decreasing = TRUE)
upb$rank[order.scores] <- 1:nrow(upb)
head(upb)
keep_cells <- rownames(upb[which(upb$rank < ncells),])
pb_sex_30k <- SubsetData(tenx30k, cells = keep_cells, do.clean = TRUE, subset.raw = TRUE)
```

## B. Filter Out Poor-Quality Cells

plot the cells:
```{r}
#inspect the ngenes and nUMI
gene_plot_30k <- VlnPlot(object = pb_sex_30k, features = "nFeature_RNA", pt.size = 0.01, do.return = TRUE)

gene_plot_30k <- gene_plot_30k + 
  geom_abline(intercept = 200, col="blue") +
  labs(x = "",y = "nGene", title = "Genes per cell") +
  theme_classic() +
  scale_fill_manual(values="grey") +
  scale_y_continuous(limits = c(0, 3000)) +
  theme(legend.position="none", axis.text.x = element_blank(), axis.ticks.x=element_blank(), text = element_text(size=20), legend.text=element_text(size=20), axis.text=element_text(size=20), axis.text.y=element_text(colour="black"))

#nUMI plot
numi_plot_30k <- VlnPlot(object = pb_sex_30k, features = "nCount_RNA", pt.size = 0.01, do.return = TRUE)

numi_plot_30k <- numi_plot_30k +
  labs(x = "",y = "nUMI", title = "UMIs per cell") +
  theme_classic() +
  scale_fill_manual(values="grey") +
  scale_y_continuous(limits = c(0, 3000)) +
  theme(legend.position="none", axis.text.x = element_blank(), axis.ticks.x=element_blank(), text = element_text(size=20), legend.text=element_text(size=20), axis.text=element_text(size=20), axis.text.y=element_text(colour="black"))

#plot together
grid.arrange(gene_plot_30k, numi_plot_30k, ncol = 2, top=textGrob("30K cells 10X", gp=gpar(fontsize=15,font=8)))
```

The threshold used in the malaria cell atlas was 230 for Pb but this is dependent on sequencing depth etc.
We can plot the number of cells recovered for a range of thresholds:
```{r}
nrow(pb_sex_30k@meta.data[pb_sex_30k@meta.data$nFeature_RNA > 150, ])
nrow(pb_sex_30k@meta.data[pb_sex_30k@meta.data$nFeature_RNA > 200, ])
nrow(pb_sex_30k@meta.data[pb_sex_30k@meta.data$nFeature_RNA > 230, ])
```

Since we have already filtered on nUMI, we will filter with 200.

```{r}
## number of cells before filtering
pb_sex_pre_filter_nCells <- nrow(pb_sex_30k@meta.data)
## filter object
pb_sex_30k <- subset(pb_sex_30k, subset = nFeature_RNA > 200)
## number of cells after filtering
pb_sex_post_filter_nCells <- nrow(pb_sex_30k@meta.data)
## print results of filtering
pb_sex_pre_filter_nCells
pb_sex_post_filter_nCells
```

save ngene plot
```{r}
ggsave("ngene_plot.pdf", plot = gene1, device = "pdf", height = 5, width = 5, units = "in", path = "/Users/ar19/Desktop/PhD/GCSKO_Analysis")
```

```{r, echo = FALSE}
pb_sex_pre_filter_nCells - pb_sex_post_filter_nCells
```
cells were removed by filtering on number of genes.

## C. Dimensionality Reduction and Clustering 

normalise
```{r}
## normalise object
pb_sex_30k <- NormalizeData(pb_sex_30k, normalization.method = "LogNormalize", scale.factor = 10000)
```

find variable genes
```{r}
pb_sex_30k <- FindVariableFeatures(pb_sex_30k, selection.method = "vst", nfeatures = 2000)
```

scale the data
```{r}
all.genes <- rownames(pb_sex_30k)
pb_sex_30k <- ScaleData(pb_sex_30k, features = all.genes)
```

```{r}
pb_sex_30k <- RunPCA(pb_sex_30k, features = VariableFeatures(object = pb_sex_30k))
```

```{r}
DimPlot(pb_sex_30k, reduction = "pca")
```

```{r}
ElbowPlot(pb_sex_30k, ndims = 30, reduction = "pca")
```

```{r}
pb_sex_30k <- FindNeighbors(pb_sex_30k, dims = 1:21)
pb_sex_30k <- FindClusters(pb_sex_30k, resolution = 1)
```

```{r}
pb_sex_30k <- RunUMAP(pb_sex_30k, dims = 1:5, seed.use = 2000, n.neighbors = 200)
DimPlot(pb_sex_30k, reduction = "umap", group.by = "ident", label = TRUE)
```

colour with a few marker genes:

```{r, fig.height = 6, fig.width = 8}
# PBANKA-0515000 - p25 - female
# PBANKA-1212600 - HAP2 - male
# PBANKA-0600600 - NEK3 - male
# PBANKA-0831000 - MSP1 - late asexual
# PBANKA-1315700 - RON2 - (asexuals and some male?)
# PBANKA-0416100 - dynenin heavy chain - male - used in 820 line
# PBANKA-1319500 - CCP2 - female - used in 820 line 
# PBANKA-1437500 - AP2-G - seuxal commitment gene
# PBANKA-1102200 - MSP8 - early asexual (from Bozdech paper)

FeaturePlot(pb_sex_30k, features = c("PBANKA-0515000", "PBANKA-1212600","PBANKA-0600600", "PBANKA-0831000", "PBANKA-1315700", "PBANKA-0416100", "PBANKA-1319500", "PBANKA-1437500", "PBANKA-1102200"))
```

## D. Remove Doublets

```{r}
#devtools::install_github('chris-mcginnis-ucsf/DoubletFinder')
#library(doubletFinder) #allows removal of doublets
# the tutorial recommends using this as an approximation:
#nExp_poi <- round(0.15*nrow(pb_sex_30k@meta.data))
#but a more appropriate approximation is that the expected number of doublets is ~1% per 1000 cells so:
nExp_poi <- round((0.01*(nrow(pb_sex_30k@meta.data)/1000))*nrow(pb_sex_30k@meta.data))
#run doublet finder:
pb_sex_30k <- doubletFinder_v3(pb_sex_30k, PCs = 1:21, pN = 0.25, pK = 0.01, nExp = nExp_poi, reuse.pANN = FALSE, sct = FALSE)
```

results in:
```{r}
table(pb_sex_30k@meta.data$DF.classifications_0.25_0.01_19402)
```

visualise where doublets are:
```{r}
doublet.cells <- c(rownames(pb_sex_30k@meta.data[pb_sex_30k@meta.data$DF.classifications_0.25_0.01_19402 == "Doublet",]))
d2 <- DimPlot(pb_sex_30k, reduction = "umap", cells.highlight = doublet.cells, sizes.highlight = 2)
doublet2 <- d2 + coord_fixed() + theme(axis.text.x=element_blank())
doublet2
```

```{r}
VlnPlot(object = pb_sex_30k, features = "pANN_0.25_0.01_19402", pt.size = 0.01)
```


```{r}
df <- pb_sex_30k@meta.data
df <- df[,c(6,8)]
df <- data.frame(rbind(table(df)))
df$pc_doublet <- ((df[,1])/((df[,1]) + df[,2]))*100
df$cluster <- rownames(df)
#plot
kable(df[order(df$pc_doublet),])
```

```{r}
ggplot(data=df, aes(x=cluster, y=pc_doublet)) +
  geom_col(fill="steelblue") +
  theme_minimal()
```

The clusters with the least doublets:
0 - asex 1
1 - asex 2
10 - female

remove doublets:
```{r}
keep_singlets <- rownames(pb_sex_30k@meta.data[pb_sex_30k@meta.data$DF.classifications_0.25_0.01_19402 == "Singlet",])
pb_30k_sex_filtered <- subset(pb_sex_30k, cells = keep_singlets, subset.raw = TRUE)
pb_sex_30k
pb_30k_sex_filtered
```

## E. Life Cycle Stage (Using Bulk RNA-Seq Correlation)

Add in bulk data predictions

### hoo et al.
```{r hoo 30k}
#Pb Prediction correlations with bulk data (asexual hoo): 

#Load in required package:
library(Hmisc)
#Cooerce expression data into a matrix and load in the reference timecourse data:
x10 <- as.matrix(pb_30k_sex_filtered@assays$RNA@data)
rownames(x10) <- gsub("-", "_", rownames(x10))
#read in bulk data:
hoo<-as.matrix(read.table("Reference_bulk_data/hoo_berg2.txt",header=T, row.names=1))
#Make a blank dataframe in which to add prediction:
df <- data.frame(matrix(ncol = 4, nrow = 0))
colnames(df) <- c("Prediction(Spearman)","r(Spearman)","Prediction(Pearsons)","r(Pearsons)")
#Do correlations with bulk data using both Spearman and Pearson (and the top 1000 genes):
for (i in 1:ncol(x10))
{
  shared<-intersect(row.names(as.matrix(head(sort(x10[,i], decreasing=TRUE),1000))),row.names(hoo))
  step0<-rcorr(x10[shared,i],hoo[shared,1:12],type = "spearman")
  step1<-as.matrix(t(step0$r[2:13,1]))
  step2<-rcorr(x10[shared,i],hoo[shared,1:12],type = "pearson")
  step3<-as.matrix(t(step2$r[2:13,1]))
  step4<-cbind(colnames(step1)[which.max(step1)],step1[which.max(step1)],colnames(step3)[which.max(step3)],step3[which.max(step3)])
  colnames(step4) <- c("Prediction(Spearman)","r(Spearman)","Prediction(Pearsons)","r(Pearsons)")
  rownames(step4)<-colnames(x10)[i]
  df<-rbind(df,step4)
}
#Write out data into a csv file:
#write.csv(dfringr,file="/Users/ar19/Desktop/PhD/AR04_GCSKO_project/All_mutants_Feb_2018/predictionpbcombined.csv")
#Change the format of the output to make it more readable:
#gsub("Pb_","", dfringr[,1]) - Make predictions into 18hr.dat format:

#spearman:
df[,1] <- gsub("Pb_","", df[,1])
#Remove hr.dat from list:
df[,1] <- gsub("hr.dat","", df[,1])
#Check - dfringr[,1]
#Make into a number:
df[,1] <- as.numeric(df[,1])
df[,2] <- as.numeric(as.character(df[,2]))

#pearson:
df[,3] <- gsub("Pb_","", df[,3])
#Remove hr.dat from list:
df[,3] <- gsub("hr.dat","", df[,3])
#Check - dfringr[,1]
#Make into a number:
df[,3] <- as.numeric(df[,3])
df[,4] <- as.numeric(as.character(df[,4]))
#add to 10X object:
pb_30k_sex_filtered <- AddMetaData(pb_30k_sex_filtered, metadata = df)
```

### Kasia's data
Can also do with Kasia's timecourse data:
```{r kasia_30k}
kas<-as.matrix(read.table("Reference_bulk_data/AP2OETC.txt",header=T, row.names=1))
#Make a blank dataframe in which to add prediction:
dfs <- data.frame(matrix(ncol = 4, nrow = 0))
colnames(dfs) <- c("ID","Prediction","r (Pearson)")
#Do correlations with bulk data using both Spearman and Pearson (and the top 1000 genes):
for (i in 1:ncol(x10))
{
  shared<-intersect(row.names(as.matrix(head(sort(x10[,i], decreasing=TRUE),1000))),rownames(kas))
  step0<-rcorr(x10[shared,i],kas[shared,1:10],type = "spearman")
  step1<-as.matrix(t(step0$r[2:11,1]))
  step2<-rcorr(x10[shared,i],kas[shared,1:10],type = "pearson")
  step3<-as.matrix(t(step2$r[2:11,1]))
  step4<-cbind(colnames(step1)[which.max(step1)],step1[which.max(step1)],colnames(step3)[which.max(step3)],step3[which.max(step3)])
  colnames(step4) <- c("Prediction(Spearman)","r(Spearman)","Prediction(Pearsons)","r(Pearsons)")
  rownames(step4)<-colnames(x10)[i]
  dfs<-rbind(dfs,step4)
}
#Write out data into a csv file:
#write.csv(df,file="/Users/ar19/Desktop/PhD/AR04_GCSKO_project/All_mutants_Feb_2018/predictionkasiacombined.csv")

#Change the format of the output to make it more readable:
#gsub("Pb_","", dfs[,1]) - Make predictions into 18hr.dat format:
dfs[,1] <- gsub("X","", dfs[,1])
#Make into a number:
dfs[,1] <- as.numeric(dfs[,1])
#Make into a number:
dfs[,2] <- as.numeric(as.character(dfs[,2]))

#gsub("Pb_","", dfs[,1]) - Make predictions into 18hr.dat format:
dfs[,3] <- gsub("X","", dfs[,3])
#Make into a number:
dfs[,3] <- as.numeric(dfs[,3])
#dfs[,1]
#Make into a number:
dfs[,4] <- as.numeric(as.character(dfs[,4]))

colnames(dfs) <- c('Prediction(Spearman)_Kasia', 'r(Spearman)_Kasia', 'Prediction(Pearson)_Kasia', 'r(Pearson)_Kasia')
#add to Seurat:
#add to 10X object:
pb_30k_sex_filtered <- AddMetaData(pb_30k_sex_filtered, dfs)
```

## confirm identities

```{r}
pb_30k_sex_filtered <- RunUMAP(pb_30k_sex_filtered, dims = 1:21, seed.use = 800, n.neighbors = 200)
DimPlot(pb_30k_sex_filtered, reduction = "umap", group.by = "ident", label = TRUE)
```

Confirm life cycle designations:

```{r}
pb_30k_sex_filtered@meta.data
FeaturePlot(pb_30k_sex_filtered, features = c("Prediction(Spearman)_Kasia", "Prediction(Spearman)"))
```

```{r}
FeaturePlot(pb_30k_sex_filtered, features = c("PBANKA-0515000", "PBANKA-1212600","PBANKA-0600600", "PBANKA-0831000", "PBANKA-1315700", "PBANKA-0416100", "PBANKA-1319500", "PBANKA-1437500", "PBANKA-1102200"))
```

N.B. These UMAPs are computed with the statistics of the doublet containing object so we will recalculate these in the next script

```{r}
pb_30k_sex_filtered <- RunPCA(pb_30k_sex_filtered, features = VariableFeatures(object = pb_30k_sex_filtered))
```

```{r}
pb_30k_sex_filtered <- RunUMAP(pb_30k_sex_filtered, reduction = "pca", dims = 1:8, n.neighbors = 50, seed.use = 1234, min.dist = 0.5, repulsion.strength = 0.05)
DimPlot(pb_30k_sex_filtered, reduction = "umap", group.by = "ident", label = TRUE)
```

```{r}
table(pb_30k_sex_filtered@meta.data$seurat_clusters)
```

subsample
```{r}
pb_30k_sex_filtered_subsample <- SubsetData(pb_30k_sex_filtered, max.cells.per.ident = 2000)
```

```{r}
pb_30k_sex_filtered_subsample <- FindVariableFeatures(pb_30k_sex_filtered_subsample, selection.method = "vst", nfeatures = 1000)
pb_30k_sex_filtered_subsample <- RunPCA(pb_30k_sex_filtered_subsample, features = VariableFeatures(object = pb_30k_sex_filtered_subsample))
```

```{r}
pb_30k_sex_filtered_subsample <- RunUMAP(pb_30k_sex_filtered_subsample, reduction = "pca", dims = 1:9, n.neighbors = 50, seed.use = 1234, min.dist = 0.5, repulsion.strength = 0.05)
DimPlot(pb_30k_sex_filtered_subsample, reduction = "umap", group.by = "ident", label = TRUE)
```

```{r, fig.width = 10, fig.length = 10}
FeaturePlot(pb_30k_sex_filtered_subsample, features = c("PBANKA-0515000", "PBANKA-1212600","PBANKA-0600600", "PBANKA-0831000", "PBANKA-1315700", "PBANKA-0416100", "PBANKA-1319500", "PBANKA-1437500", "PBANKA-1102200"))
```


# Save and Export {.tabset}

This saves everything in the global environment for easy recall later
```{r}
save.image(file = "GCSKO_10X_QC.RData")
#load(file = "GCSKO_10X_QC.RData")
```

Specifically, pb_30_sex_filtered & are needed for Part 2
```{r}
save(pb_30k_sex_filtered, pb_sex_filtered, file = "Part_2_input.Rdata")
#load(file = "Part_2_input.Rdata")

saveRDS(pb_30k_sex_filtered, file = "pb_30k_sex_filtered.RDS", compress = FALSE) 
#pb_30k_sex_filtered <- readRDS("pb_30k_sex_filtered.RDS")

save(pb_30k_sex_filtered,file="pb_30k_sex_filtered.Robj")


saveRDS(pb_sex_filtered, file = "pb_sex_filtered.RDS") 
#pb_sex_filtered <- readRDS("pb_sex_filtered.RDS")

```

# Appendix {.tabset}

## Session Info 
```{r, echo = FALSE}
sessionInfo()
```

